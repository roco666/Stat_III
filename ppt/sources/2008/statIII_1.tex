%\documentclass[style=heg, mode=print]{powerdot}
\documentclass[style=heg]{powerdot}

\usepackage{amsfonts}
\usepackage{pst-plot}
	% Pour la c\'esure des mots
\usepackage[T1]{fontenc}
	% Pour traduire par exemple Chapter -> Chapitre
\usepackage[frenchb]{babel}
\StandardLayout
	% Chemin des graphiques
\graphicspath{{../fig/}}

% Definitions Maths
\newcommand{\IN} {\mathbb{N}}
\newcommand{\ZZ} {\mathbb{Z}}
\newcommand{\IR} {\mathbb{R}}
\newcommand{\IB} {\mathbb{B}}
\def\X{\mathop{\lower 2pt\hbox{\large{\textsf X}}}}
\newcommand{\var} {{\rm var}}
\newcommand{\cov} {{\rm cov}}
\newcommand{\corr} {{\rm corr}}
\newcommand{\E}{{\rm E}}
\newcommand{\biais}{{\rm biais}}
\newcommand{\med}{{\rm med}}
\newcommand{\prob}{{\rm Pr}}
\newcommand{\bin}{\mathcal{B}}
\newcommand{\binneg}{\mathcal{BN}}
\newcommand{\pois}{\mathcal{P}}
\newcommand{\hyperg}{\mathcal{H}}
\newcommand{\norm}{\mathcal{N}}
\newcommand{\unif}{\mathcal{U}}
\newcommand{\st}{\mathcal{T}}
\newcommand{\ki}{\mathcal{\chi}}

	%\Logo{\includegraphics[scale=0.35]{heg}}
\title{Statistique inférentielle}
\author{Dr. Sacha Varone}
\date{}
\pdsetup{
rf={\tiny stat III - cours 1}
}

\begin{document}
\maketitle

\begin{slide}[toc=]{Objectif}
Savoir reconnaître et utiliser une loi normale.
\end{slide}

\section{Inférence statistique}
\begin{slide}{Termes}
\begin{itemize}
	\item Une \emph{unité statistique} est le plus petit élément sur lequel
porte l'analyse statistique.
  \item Une \emph{variable statistique} est une caractéristique d'une
unité statistique.
  \item Une \emph{population} est un ensemble de toutes les unités statistiques sur lequel porte une étude
statistique.
  \item Un \emph{échantillon} est un sous-ensemble de la population.
\end{itemize}
\end{slide}

\begin{slide}[toc=]{Termes}
\begin{itemize}
	\item Statistique descriptive\\
	Décrire avec des graphiques, résumé par des chiffres clés\\
	\'Elaborer des hypothèses de travail pouvant être vérifiés en statistique inférentielle. 
  \item Statistique inférentielle\\
  \`A partir d'un échantillon de données, inférer sur la population.\\
  Utilisation de la théorie des probabilités.\\
  But: estimer et tester.
\end{itemize}
\end{slide}

\begin{slide}[toc=]{Inférence}
$$\includegraphics[scale=0.6]{inference.eps}$$
\end{slide}

\begin{slide}[toc=]{Termes}
\begin{itemize}
	\item Un \emph{paramètre} est une mesure calculée à partir d'une population entière.
  \item Une \emph{statistique} est une mesure calculée à partir d'un échantillon.
  \item L'\emph{erreur d'échantillonnage} est la valeur de la différence entre une statistique et le paramètre évalué.
\end{itemize}
\end{slide}


\section{Distributions continues}
\begin{slide}[toc=]{Exemples}
Données continues:
\begin{itemize}
	\item quantité de panure sur les mets à base de poisson
	\item longueur de coupes d'aciers
	\item temps de recharge d'une batterie de téléphone
	\item $\ldots$
\end{itemize}

Modèle: distributions continues
\begin{itemize}
	\item loi uniforme
	\item loi normale
	\item loi exponentielle
	\item $\ldots$
\end{itemize}
\end{slide}

\begin{slide}{V.A. continue}
\begin{itemize}
	\item Une variable aléatoire continue $X$ prend ses valeurs dans un intervalle qui est un sous-ensemble de l'ensemble des réels $\IR$ :
  \item Le nombre de valeurs possibles de $X$ étant infini, chacune de ces valeurs a une probabilité nulle.
  \item En revanche,
  $$\begin{array}{ll}
	P(X = x) = 0 & \forall x \in [v,w]\\
  P(X \in [a, b]) \geq 0 & \forall a < b, [a, b] \subseteq [v,w]$$
\end{array}$$
\end{itemize}
\end{slide}

\begin{slide}{Fonction de densité}
\begin{itemize}
	\item Une distribution continue -> histogramme -> fonction de densité $f(x)$
  \item La fonction de densité n'est pas une distribution de probabilité: $P(X = x) = 0$, mais $f(x) \geq 0$.
  \item En revanche, l'aire sous la courbe d'une fonction de densité doit valoir 1,
$$P(X \in ] -\infty,\infty[) = 1$$
\end{itemize}
\end{slide}

\begin{slide}{Fonction de répartition}
$$P(X \in [x, x + dx]) = f(x) dx$$

La probabilité de se trouver dans un intervalle $[a, b]$ est définie comme l'{\red aire} sous la fonction de densité.
Mathématiquement, cela revient à calculer l'intégrale de la fonction $f(x)$ entre $a$ et $b$ :
$$P(X \in [a, b]) = \int^b_a f(x) dx$$

La fonction de répartition, notée $F(x)$, exprime pour une variable aléatoire $X$ la probabilité d'être inférieure ou égale à $x$. Cela correspond à la surface sous la fonction de densité à gauche de $x$ :
$$F(a) = P(X \leq a) = \int^a_{-\infty} f(x) dx$$
\end{slide}

\begin{slide}[toc=]{Propriétés}
\begin{itemize}
	\item $F(-\infty) = 0$, 
	\item $F(\infty) = 1$
	\item $P(X <a) = P(X \leq a) = F(a)$
  \item $P(X \in [a, b]) = F(b) - F(a)$
  \item Par complémentarité, $P(X>a) = 1- P(X\leq a) = 1-F(a)$
\end{itemize}
\end{slide}

\section{Loi normale}
\begin{slide}{Introduction}
Loi la plus utilisée pour décrire des phénomènes par une variable aléatoire continue : loi normale.
\\[5mm]
Exemples:\\
description du poids, de la taille, du remplissage de récipients, ... 
\\[5mm]
Abondamment utilisée lors de l'inférence statistique.
\end{slide}

\begin{slide}[toc=Graphique]{Représentation graphique}
En forme de cloche, symétrique.
$$\includegraphics[scale=0.35]{norm_0_1}$$
\end{slide}

\begin{slide}{Propriétés}
\begin{itemize}
	\item Le point le plus élevé de la courbe normale correspond à la moyenne, qui est aussi la médiane et le mode de la distribution.
  \item La distribution normale étant symétrique, son  coefficient d'asymétrie (skewness) est nul.
\end{itemize}
\end{slide}

\begin{slide}[toc=Densité]{Densité de probabilité normale}
La \emph{densité de probabilité normale} s'exprime par
$$f(x)=\frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}$$
où $\mu$ est la moyenne et $\sigma$ est l'écart type
\end{slide}

\begin{slide}{Remarque}
La loi normale, notée $\norm (\mu,\sigma^2)$, comporte deux paramètre $\mu$ et $\sigma^2$, qui déterminent la position et la forme de la distribution.
$$X\in ]-\infty, \infty [ \quad\quad\quad X\sim  \norm (\mu,\sigma^2)$$
$\sigma^2$ détermine la largeur de la courbe. Plus sa valeur est élevée, plus la courbe sera large et aplatie.\\
$\mu$ détermine la position de la moyenne.\\[5mm]
Il existe donc une famille de lois normales, et non pas une seule, qui se différencient par leur moyenne et leur écart type.
\end{slide}

\begin{slide}[toc=]{Famille de lois normales}
$$
\includegraphics[scale=0.3]{normalesMu0}
\includegraphics[scale=0.3]{normalesV1}$$
\end{slide}

\begin{slide}{Probabilités}
Probabilité -> aire sous la courbe de densité $f(x)$. \\[5mm]
Par Symétrie $P(X\leq\mu)=P(X\geq\mu)=0.5$\\
Donc $P(X\leq x) = 1-P(X\geq x)$
$$\includegraphics[scale=0.35]{norm_table}$$
\end{slide}


\begin{slide}[toc=Définition]{Normale centrée réduite}
Une loi normale de moyenne nulle et d'écart type 1, écrite $\norm (0,1)$, est dite \emph{loi normale centrée réduite}. La fonction de densité est alors
$$f(x)=\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}}$$
\end{slide}

\begin{slide}{Transformation}
$$X\sim \norm (\mu,\sigma^2)\quad\Rightarrow\quad Z=\frac{X-\mu}{\sigma}\sim\norm (0,1)$$
Les probabilités suivantes sont alors équivalentes

$$X\leq x\quad\Rightarrow\quad Z\leq\frac{x-\mu}{\sigma}$$
$$P(X\leq x)=P(Z\leq\frac{x-\mu}{\sigma})$$
\end{slide}

\begin{slide}[toc=]{Exemple}
Soit $X$ est une variable aléatoire suivant une loi normale de centre $\mu=100$ et d'écart-type $\sigma=50$, i.e. 
$$X\sim\norm (100,2500) \quad\quad Z=\frac{X-\mu}{\sigma}\sim\norm (0,1)$$

$\begin{pspicture}(-1.5,0)(1.5,3.1)
\psset{linewidth=0.5pt,xunit=3cm,yunit=3cm}
\parametricplot[plotpoints=100]{-0.5}{2.5}{t 1 0.5 2 3.1416 mul sqrt mul div 2.71828 t 1 sub 2 exp 2 0.5 2 exp mul div neg exp mul}
\psaxes[arrowscale=1.5,ticks=none,labels=none]{->}(-0.5,0)(2.5,1.0)
\psline(1,-0.1)(1,0.1)
\uput[90](1.0,-0.3){100}
\uput[90](1.0,-0.45){\red 0}
\psline(2.0,-0.1)(2.0,0.1)
\uput[90](2.0,-0.3){200}
\uput[90](2.5,-0.3){X}
\uput[90](2.0,-0.45){\red 2}
\uput[90](2.5,-0.45){\red Z}
\uput[90](2,0.8){$X\sim\norm (100,2500)$}
\uput[90](2,0.5){\red $Z\sim\norm (0,1)$}
\end{pspicture}$
\\[15mm]
Si $X=200$ alors  $Z=\frac{200-100}{50}=2$\\
Et donc $\mu + 2 \sigma = 100+2*50 = 200 = X$
\end{slide}

\begin{slide}[toc=Table]{Table de la loi normale}
La table de la loi normale donne les probabilités d'occurrence jusqu'à la z-valeur considérée. La ligne donne la valeur de Z jusqu'au dixième, et la colonne donne la valeur de z au centième.\\[5mm]

{\footnotesize
\begin{tabular}{r|rrrrrr}

         z &       0.00 &       0.01 &       0.02 &       0.03 &       0.04 & ...\\
\hline
           &            &            &            &            &            \\

         0 &     0.5000 &     0.5040 &     0.5080 &     0.5120 &     0.5160  & ...\\

       0.1 &     0.5398 &     0.5438 &     0.5478 &     0.5517 &     0.5557  & ...\\

       0.2 &     0.5793 &     0.5832 &     0.5871 &     0.5910 &     0.5948  & ...\\

       0.3 &     0.6179 &     0.6217 &     0.6255 &     0.6293 &     0.6331  & ...\\

       0.4 &     0.6554 &     0.6591 &     0.6628 &     0.6664 &     0.6700   & ...\\

           &            &            &            &            &            \\

       0.5 &     0.6915 &     0.6950 &     0.6985 &     0.7019 &     0.7054  & ...\\

       0.6 &     0.7257 &     0.7291 &     0.7324 &     0.7357 &     0.7389  & ...\\

       0.7 &     0.7580 &     0.7611 &     0.7642 &     0.7673 &     0.7704  & ...\\

       0.8 &     0.7881 &     0.7910 &     0.7939 &     0.7967 &     0.7995  & ...\\

       0.9 &     0.8159 &     0.8186 &     0.8212 &     0.8238 &     0.8264  & ...\\
       ...  & ...  & ...  & ...  & ...  & ...  & ...
\end{tabular}
}
\end{slide}

\begin{slide}[toc=]{Exemple}
\begin{itemize}
	\item La z-valeur associée à la ligne 0.5 et à la colonne 0.01 correspond à Z=0.51.\\
L'intersection de la ligne et de la colonne donne la probabilité cherchée:\\
$P(Z\leq 0.51)=0.6950$
  \item $P(Z\geq 0.51)=1-0.6950 = 0.305$ par complémentarité.
  \item $P(Z\leq -0.51) = P(Z\geq 0.51) = 0.305$ par symétrie.
\end{itemize}
\end{slide}
%
\begin{slide}{Règle empirique}
En pratique: de nombreux ensembles de données ont une distribution en forme de cloche.\\
	\begin{itemize}
		\item Environ 68\% des observations se situent dans l'intervalle $[\bar{x}-s;\bar{x}+s]$
		\item Environ 95\% des observations se situent dans l'intervalle $[\bar{x}-2s;\bar{x}+2s]$
		\item Environ 99.7\%  des observations (presque toutes) se situent dans l'intervalle\\ $[\bar{x}-3s;\bar{x}+3s]$
	\end{itemize}
\end{slide}

\begin{slide}[toc=Valeurs singulières]{Détection de valeurs singulières}
Les variables centrées réduites $Z$ permettent de détecter des valeurs singulières\\[5mm]

Les données éloignée de la moyenne de plus de 3 écarts type sont très peu probables (Z>3).\\
$\Rightarrow$ données {\red singulières}
\end{slide}

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
